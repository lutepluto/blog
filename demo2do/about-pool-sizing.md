# 连接池大小相关

在日常的开发工作中，如何配置数据库连接池的大小看似简单却暗藏玄机。实际上，配置数据库连接池需要首先明白几个原则，有些原则甚至与你的直觉正好相悖。假设你拥有一个虽然没有 Facebook 那样体量，但也需要同时支撑10000个前台用户发起数据库查询，带来每秒约20000事务。那你的数据库连接应该多大呢？你可能会感到非常惊讶这不是一个数据库连接应该多大，而是多小的问题。

### 原因何在

大家可能都应该理解在计算的其他方面「少即是多」（less is more）。为什么一台仅有4个线程的 Nginx 服务器可以击败一台用有100个进程的 Apache 服务器？如果你回想一下计算机科学概论，这是不是一件显而易见的事？

即时一台单核 CPU 的电脑也能支持上百个线程同时工作。但我们都知道这只不过是操作系统分时调度（time-slicing）的小把戏。实际上，单核 CPU 在某一时间只能执行一个线程；之后操作系统会切换上下文环境（context），CPU 再去执行另一个线程上的代码。CPU 会一直重复这个执行，切换，执行的过程。根据计算的基本法则，给定单个 CPU 资源，顺序的执行任务 A 和 任务 B 总是会比利用分时调度“同时”执行任务 A 和 B 来的快。一旦线程的数量超过 CPU 的数量，增加更多的线程只会减慢处理速度而不是想象中的加快。这几乎是可以肯定的...

### 有限的资源

虽然实际情况并不像上面讲的那么简单，但也很接近了。实践中还有一些其他的影响因素。当分析数据库的主要瓶颈有哪些时，我们可以把它们分为3大类：CPU，硬盘，网络。内存本也可以考虑在内，但与硬盘和网络相比存在带宽上几个数量级的差异。（We could add Memory in there, but compared to Disk and Network there are several orders of magnitude difference in bandwidth.）

如果我们忽略掉硬盘和网络，事情就变得简单了。在一台8核服务器上，设置连接大小为8会获得最优性能，超过这个数字就会由于上下文环境切换的开销开始拖慢处理速度。但是我们不能忽略硬盘和网络。数据库一般会将数据存储在硬盘上，而传统硬盘则是由旋转金属板和安装在步进电机驱动臂上的读写磁头组成。读写磁头某一时间只能在一个位置上（为单词查询读／写数据）。为不同的查询读写数据则要求磁头必须“查找”硬盘上的新位置。所以这里还有“查找”时间的消耗以及为了读写数据必须等待磁片旋转到合适位置所消耗的时间。这里当然可以利用缓存提升效率，但我们刚才阐述的原则仍然适用。

在等待读写的时间里（I/O 阻塞），连接／查询／线程为了等待硬盘而被“阻塞”了。在这段时间内，操作系统就可以通过执行其他线程的代码来实现 CPU 资源的更合理分配。因此，如果连接／线程的数量多于物理内核的数量，由于线程会被 I/O 阻塞，计算机就可以完成更多的工作。

那究竟需要多少连接／线程呢？需要多少的问题还要考虑到硬盘子系统，因为新型的 SSD 硬盘并不需要处理“查找”或旋转磁盘的额外工作。但请不要误以为“SSD 更快所以我可以创建更多的线程”。更快的读写速度，无需磁头查找和磁盘旋转意味着阻塞更少，因此更少的线程（更接近于 CPU 数量）反而会比更多的线程性能更好。只有在阻塞为执行任务创造越多机会的时候，越多的线程才使计算机性能越好。

网络的因素与硬盘类似。当发送／接收缓冲区被填满，通过以太网接口向网络发送数据同样会引起阻塞。10兆接口会比千兆以太网慢，而千兆以太网又会比百万兆慢。但网络和资源阻塞相比只能排在其后，所以许多人就直接将网络因素忽略了。

![PostgreSQL benchmark](https://github.com/brettwooldridge/HikariCP/wiki/Postgres_Chart.png)

从上图中可以看到，在 PostgreSQL 的基准测试中，TPS 在50个连接左右逐渐趋于平稳。

### 公式

下面的公式时基于 PostgreSQL 项目为起点的，但我们相信它适用于大部分数据库。你可以测试你自己的应用，例如模拟期望的负荷，然后在这个起点周围尝试不同的连接池配置。

***连接数 = ((内核数量 * 2) + 有效转轴数)***

```
内核数量不能包含 HT threads，即使超线程（hyperthreading）可用。如果有效数据集被完全缓存，有效转轴数（effective spindle count）则为0。当缓存命中率下降时，有效转轴数则越接近于实际值。目前为止这个公式在 SSD 上工作如何并没有得到任何证明。
```

如果你拥有一台4核i7，一块独立硬盘的服务器，则连接池的大小为：`9 = ((4 * 2) + 1)`。可以取`10`为近似值。感觉太小了？那你不妨真的尝试一下，我们敢打赌你可以轻松的应对3000个前台用户发起简单查询，差不多6000 TPS。如果你跑一下压力测试，你可以看到在把连接池大小调高超过10后，TPS 应该会逐渐放缓，前台反应速度也会开始变慢。

### "Pool-locking"

如果单一操作多次获取连接则有可能出现“连接池锁定”（pool-locking）的问题。这是一个应用级的问题。加大连接池大小的确可以减小锁定的概率，但我们还是敦促你在加大连接池之前看看能在应用级别做些什么。

为避免死锁的连接池大小计算公式：

  pool size = T<sub>n</sub> * (C<sub>m</sub> - 1) + 1

举个例子，你有最多8个线程（T<sub>n</sub>=8），每一个线程需要3个连接来执行某项任务（C<sub>m</sub>=3）。那确保不会出现死锁的连接池大小则为：

  pool size = 8 * (3 - 1) + 1 = 17

**这不一定是最佳连接池大小，但最少需要这么大的连接池来避免死锁。**

**在某些环境中，使用 JTA，在当前事务中，通过从`getConnection()`返回给一个已经获取连接的线程相同的连接可以极大减少连接数量。**

### 注意事项

不同的部署实例，连接池的设置大小可能完全不同。

举例来说，一个混有长时间运行事务和非常短时事务的系统是很难调优连接池的。在这种情况下，创建两个连接池是更好的选择（一个连接池为长时间运行事务服务，另一个为“实时”查询服务）。

在一个主要是长时间运行事务的系统中，通常会有对连接池有“外部”约束条件，例如一个一次只允许一定数量任务执行的任务队列。在这种场景下，队列大小需要“匹配”连接池大小（而不是其他方式）。





